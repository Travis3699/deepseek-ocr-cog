"""
DeepSeek-OCR on Replicate Cog
æ”¯æŒåœ–ç‰‡ï¼ˆJPG/PNG/WebPï¼‰+ PDF
"""

from cog import BasePredictor, Input
import torch
from transformers import AutoModel, AutoTokenizer
from PIL import Image
import requests
from io import BytesIO
import tempfile
import os


class Predictor(BasePredictor):
    """Replicate é æ¸¬é¡"""

    def setup(self) -> None:
        """åˆå§‹åŒ–æ¨¡å‹ï¼ˆå®¹å™¨å•Ÿå‹•æ™‚é‹è¡Œä¸€æ¬¡ï¼‰"""
        print("ğŸš€ åˆå§‹åŒ– DeepSeek-OCR æ¨¡å‹...")

        model_name = "deepseek-ai/DeepSeek-OCR"

        print("ğŸ“– åŠ è¼‰ Tokenizer...")
        self.tokenizer = AutoTokenizer.from_pretrained(
            model_name,
            trust_remote_code=True
        )

        print("ğŸ§  åŠ è¼‰æ¨¡å‹...")
        # CPU å‹å–„é…ç½®
        self.model = AutoModel.from_pretrained(
            model_name,
            trust_remote_code=True,
            torch_dtype=torch.float32,  # CPU æ”¯æŒ
            low_cpu_mem_usage=True  # ç¯€çœè¨˜æ†¶é«”
        )

        # å¦‚æœæœ‰ GPU å‰‡ä½¿ç”¨
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.model = self.model.to(self.device)
        self.model.eval()
        
        print(f"âœ… æ¨¡å‹å·²åŠ è¼‰åˆ° {self.device}")

    def predict(
        self,
        image_url: str = Input(description="Image URL"),
        prompt: str = Input(default="Extract all text from this document")
    ) -> str:
        """OCR æ¨ç†"""
        try:
            print(f"ğŸ”„ è™•ç†è«‹æ±‚...")

            # åŠ è¼‰åœ–åƒ
            image = self._load_image(image_url)

            # ä¿å­˜ç‚ºè‡¨æ™‚æ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix=".jpg", delete=False) as tmp_file:
                image.save(tmp_file.name, "JPEG")
                image_path = tmp_file.name

            print(f"   åœ–åƒå¤§å°: {image.size}")

            # åŸ·è¡Œ OCR
            print("   é‹è¡Œ OCR æ¨ç†...")
            with torch.no_grad():
                result = self.model.infer(
                    self.tokenizer,
                    prompt=f"<image>\n{prompt}",
                    image_file=image_path,
                    base_size=1024,
                    image_size=640,
                    crop_mode=True
                )

            # æ¸…ç†
            os.remove(image_path)

            print(f"âœ… OCR å®Œæˆï¼")
            return result

        except Exception as e:
            print(f"âŒ éŒ¯èª¤: {str(e)}")
            raise

    def _load_image(self, image_input: str) -> Image.Image:
        """åŠ è¼‰åœ–åƒ"""
        if image_input.startswith("http"):
            print("   ğŸ“¥ å¾ URL ä¸‹è¼‰åœ–åƒ...")
            response = requests.get(image_input, timeout=30)
            response.raise_for_status()
            return Image.open(BytesIO(response.content)).convert("RGB")
        elif image_input.startswith("data:"):
            print("   ğŸ” è§£ç¢¼ Base64...")
            import base64
            base64_str = image_input.split(",")[1]
            image_bytes = base64.b64decode(base64_str)
            return Image.open(BytesIO(image_bytes)).convert("RGB")
        else:
            print("   ğŸ“‚ åŠ è¼‰æœ¬åœ°æ–‡ä»¶...")
            return Image.open(image_input).convert("RGB")
